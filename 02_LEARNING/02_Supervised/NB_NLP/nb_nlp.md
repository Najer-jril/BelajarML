# ğŸ“˜ Learning Brief â€” Naive Bayes & NLP

Dokumen ini menjelaskan **tujuan, prasyarat, dataset, alur belajar, dan output** untuk materi **Naive Bayes dan Natural Language Processing (NLP)** sesuai dengan RPS dan Sub-CPMK.

---

## ğŸ¯ Tujuan Pembelajaran

Setelah menyelesaikan fase ini, mahasiswa mampu:

* Menjelaskan konsep probabilistik Naive Bayes
* Mengimplementasi dan mengevaluasi Naive Bayes pada data tabular
* Memahami dasar Natural Language Processing (NLP)
* Mengimplementasi klasifikasi teks menggunakan Naive Bayes
* Mengevaluasi performa model NLP secara kuantitatif dan kritis

**Sub-CPMK terkait:**

> Mahasiswa mampu mengimplementasi dan mengevaluasi model naive bayes dan teknik natural language processing. (C5, P4, A4)

---

## ğŸ“Œ Prasyarat (SUDAH TERPENUHI)

âœ” Feature engineering & preprocessing
âœ” Train-test split
âœ” Classification metrics (precision, recall, F1, ROC)
âœ” Pipeline & GridSearch
âœ” Threshold tuning

> âš ï¸ Tidak perlu regresi, SVM, atau unsupervised untuk masuk ke NB & NLP

---

## ğŸ§  Konsep Inti yang Akan Dipelajari

### 1ï¸âƒ£ Naive Bayes

* Bayes Theorem
* Conditional Probability
* Asumsi **conditional independence**
* Perbedaan:

  * Gaussian Naive Bayes
  * Multinomial Naive Bayes
  * Bernoulli Naive Bayes

---

### 2ï¸âƒ£ NLP (Natural Language Processing)

* Representasi teks ke numerik
* Tokenization
* Stopwords removal
* Bag of Words
* TF-IDF
* Sparse vector & curse of dimensionality

---

## ğŸ—‚ï¸ Alur Belajar (STEP-BY-STEP)

---

## ğŸ”¹ STEP 1 â€” Naive Bayes (Tabular Data)

### Tujuan

Mengenal Naive Bayes sebagai **baseline classifier probabilistik** dan membandingkannya dengan Logistic Regression & SVM.

### Dataset

* **Boleh pakai dataset yang sama (Adult Income)**
* Tujuannya **comparative study**, bukan performa maksimal

### Aktivitas

1. Import Gaussian Naive Bayes
2. Training model
3. Evaluasi:

   * Confusion matrix
   * Precision, Recall, F1
   * ROC-AUC
4. Bandingkan dengan:

   * Logistic Regression
   * SVM

### Fokus Analisis

* Kenapa NB bisa kalah/menang?
* Pengaruh asumsi independensi
* Overfitting vs underfitting

### Output

* Notebook: `01_naive_bayes_tabular.ipynb`
* Kesimpulan komparatif model

---

## ğŸ”¹ STEP 2 â€” Transisi ke NLP (Konsep & Preprocessing)

### Tujuan

Memahami kenapa Naive Bayes **sangat cocok** untuk teks.

### Materi

* Karakteristik data teks
* Perbedaan numerik vs teks
* Masalah dimensionalitas tinggi
* Kenapa model linear & NB efektif di NLP

### Aktivitas

* Eksplorasi dataset teks
* Analisis panjang dokumen
* Distribusi kata

### Output

* Notebook: `02_nlp_text_preprocessing.ipynb`

---

## ğŸ”¹ STEP 3 â€” Feature Extraction untuk Teks

### Tujuan

Mengubah teks â†’ vektor numerik

### Teknik

1. **CountVectorizer**
2. **TF-IDF Vectorizer**

### Aktivitas

* Tokenization
* Stopwords
* N-grams (opsional)
* Bandingkan BoW vs TF-IDF

### Output

* Visualisasi sparse matrix
* Notebook: `03_text_vectorization.ipynb`

---

## ğŸ”¹ STEP 4 â€” Naive Bayes untuk NLP

### Tujuan

Membangun **text classifier berbasis probabilistik**

### Model

* Multinomial Naive Bayes

### Aktivitas

1. Pipeline:

   * Vectorizer â†’ Classifier
2. Training
3. Evaluasi:

   * Confusion matrix
   * Precision, Recall, F1
   * Precision-Recall Curve

### Dataset Contoh

* SMS Spam Detection
* Movie Review Sentiment
* Tweet Sentiment

### Output

* Notebook: `04_naive_bayes_nlp.ipynb`

---

## ğŸ”¹ STEP 5 â€” Evaluasi Kritis & Insight

### Fokus Analisis

* Precision vs Recall pada NLP
* False Positive vs False Negative
* Kapan NB lebih baik dari Logistic Regression?
* Kapan NB tidak cocok?

### Output

* Kesimpulan tertulis (Markdown / Notebook)

---

## ğŸ“ Struktur Direktori contoh

```
06_naive_bayes_nlp/
â”‚
â”œâ”€â”€ naive_bayes_tabular.ipynb
â”œâ”€â”€ nlp_text_preprocessing.ipynb
â”œâ”€â”€ text_vectorization.ipynb
â”œâ”€â”€ naive_bayes_nlp.ipynb
â””â”€â”€ README.md
```

---

## ğŸš¦ Kriteria â€œSUDAH PAHAMâ€

Kamu **boleh lanjut ke Unsupervised / DL** kalau:

* Bisa menjelaskan NB tanpa lihat rumus
* Bisa jelaskan kenapa NB cocok untuk teks
* Bisa membaca confusion matrix NLP
* Bisa menjelaskan trade-off precision vs recall

Kalau belum â†’ **belum DL**

---

## ğŸ”œ Setelah NB & NLP

Next logical step:

1. Unsupervised Learning (KMeans & PCA)
2. Baru masuk:

   * Neural Network
   * Backpropagation
   * Deep Learning

---

## ğŸ§  Catatan

> NB + NLP = **fondasi DL untuk teks**
> Kalau ini lemah â†’ DL NLP bakal kerasa â€œmagic tanpa logikaâ€.

---